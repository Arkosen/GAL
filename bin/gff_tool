#!/usr/bin/perl
use strict;
use warnings;
use Getopt::Long;
use List::Util;
use List::MoreUtils;

#-----------------------------------------------------------------------------
#----------------------------------- MAIN ------------------------------------
#-----------------------------------------------------------------------------
my $usage = '

Synopsis:

gff_tool --validate file.gff3
gff_tool --validate file.gvf

Description:

A script to do a lot of different operations on a GFF3 file.

Options:

All arguments given on the command line not associated with one of the
following argument flags are considered to be feature files to be
parsed and operated on.

--Input/Output Options--

  in_place|i      Do an in-place edit of the file. Be careful - no
		  backup copy of your original file will be created!

  out_ext|o       If input is coming from a file(s) and you want
		  output to be written to a file(s) of the same name
		  with an added extension, then give the extension
		  here and gff_tool will do the right thing by using
		  the same file name with the given argument as an
		  additional extenstion.

  fasta|j         Provide the path to a fasta file or a directory
		  containing the fasta file(s) associated with a given
		  feature file.  This argument is required by some
		  (but not all) of the other commands.  Bio::DB::Fasta
		  is used to index the fasta file.  The sequence of
		  each feature is made available to any code reference
		  given via the code argument.  See below for details
		  of code references.  Not yet implimented.

  so_file         The location of a Sequence Ontology OBO format file.
		  The location of the file may also be given with the
		  environment variable SO_OBO.  If no file is
		  available an attempt will be made to retrieve the
		  latest version from the Sequence Ontology website.

--Include/Exclude Options--

The following filters are applied in addition to any other
manipulations just before a feature (or it\'s sequence) is printed,
and so if a feature is altered by other commands the filter will apply
to the altered copy of the feature.  All filters given are applied.

  ids|d           Provide a file that contains a list of IDs (or other
		  values).  The values loaded be used by the
		  include/exclude commands described below and will
		  also be made available as a hash reference ($i) to
		  the any code reference given.

  seqids          Provide a file that contains a list of seqids.  The
		  values loaded be used by the include/exclude
		  commands described below and will also be made
		  available as a hash reference ($si) to the any code
		  reference given.

  include|n       Include only those features whos IDs match the
		  values provided by the ids argument above.

  exclude|e       Exclude those features whos IDs match the the values
		  provided by ids argument above.

  code|c          A code reference that will be used by some of the
		  following commands below and applied in turn to each
		  feature as described.  All code references will have
		  available to the the following variables:

		      $i  - A hash reference of the values loaded from the
			    file given by the ids argument.
		      $si - A hash reference of the values loaded from the
			    file given by the seqids argument.
		      $f -  A hash reference for the current feature (see
			    below for more details on the structure of the
			    hash reference).
		      $t -  A hash reference for the attributes associated
			    with the current feature (see below for more
			    details on the structure of the hash reference).
		      $s -  The sequence of the current feature.  Actually
			    $s is a a code reference that will return the
			    sequence for the current feature.  This prevents
			    the code from loading the sequence for each
			    feature unless necessary.
		      $d -  A Bio::DB::Fasta object for the fasta sequences
			    given by the fasta argument described above.

  filter|t        Use the code reference provided with the code
		  argument described above to filter the features.
		  Print only those features that return true from the
		  given code ref.

  overlaps        Print only those features whose start and end coordinates
		  overlap those given as an argument to this command.
		  Coordinates are give as seqid:start-end where start
		  defaults to 1 and end defaults start or 100,000,000,000
		  if start is also not defined.

  genes           Keep only the gene models from a complex GFF file.

--Modify Options--

  merge|m         Merge takes a feature file(s) and combines the
		  features.  If gff_tool encounters a second feature
		  that shares an ID with a previously encountered
		  feature then both of those features are passed to
		  the given code reference and the feature that is
		  returned by the code reference will be saved.  If no
		  code reference is given, then the first feature
		  encountered will be saved and a warning issued.

  blend|b	  Blend takes a feature file(s) and uniquely blends
		  the attributes for features that share the same ID.
		  If two features have the same ID, but conflict in
		  ways other than the attributes (i.e. seqid, source,
		  type, start, end, strand, phase values) then blend
		  will use any code reference provided to the code
		  argument to resolve which feature to save as
		  described above for the merge command.  If no code
		  reference is available then blend will keep the
		  values from the first feature encountered, then
		  blend the attributes and issue a warning.

  sort|s          Sort the feature file using the code reference given
		  by the code argument described above.  If no code
		  argument is given the sort will sort lexigraphically
		  on seqid and numerically on start and reverse
		  numerically on end.(Not yet implimented)

  alter|a         Apply the code reference given by the code argument
		  described above to each feature.  This is identical
		  to the filter command described above, but any
		  alteration made to the feature by the code
		  reference is kept in printing.

  hash_ag|h

		  The hash_ag function aggregates all the features in
		  a file to a hash based on user specified code.  It
		  then iterates over each key in that has and runs
		  another block of user specified code on the value(s)
		  that were stashed in that hash value. This could,
		  for examples, be used to stash all data into a hash
		  keyed off the feature type and then calculate and
		  print the averages score for each feature type.  The
		  hash_ag argument takes a code reference.  A second
		  code reference passed to the code argument is also
		  required.  The function uses the code reference
		  supplied by the code argument described above to
		  create a hash (%h).  This may be done, for example,
		  by pushing all features onto the values of %h keyed
		  by seqid or type.  After all features have been been
		  iterated over (and possibly stored) this way,
		  another loop is run over each key of %h and the code
		  reference provided to the hash_ag argument is run
		  for each iteration through that loop.  The variables
		  made available within this loop are as follows:

		      %h - The hash created as described above.
		      $k - The current key.
		      $v - The current value.

		  See the Examples section below.

--Reporting Options--

  validate|v

		  The validate command provides simple validation for
		  GFF3 and GVF files.  Constraints on values and
		  attributes are checked as described in the GFF3 and
		  GVF specification.  If a ##gvf-version pragma is
		  encountered then GVF constraints will be applied in
		  addition to GFF3 constraints, otherwise the file
		  will be validated as GFF3.  Values that are
		  constrained by the GVF or GFF3 specification to be
		  SO terms are checked but SO relationships are not
		  currently enforced.  A SO.obo file can be passed as
		  an argument to the validate argument and this file
		  will be used to validate the SO terms used in the
		  file.  If no SO file is given, gff_tools will
		  attempt to access the the current SO file from the
		  SO website.  If no SO file is available by any of
		  the above methods, then no validation of SO terms
		  will be done.  An error report will be printed to
		  STDOUT.

  stats|u	  Return simple summary statistics for the given file.
		  (Not yet implimented)

--Add/Extract Options--

  print           Just print the features - applying any include/exclude
		  along the way.

  sequence|p      Print a fasta sequence for each feature instead of
		  the feature. Requires the fasta argument (Not yet
		  implimented)

  splice_sequence Print the mature fasta sequence for spliced
		  features (exons, CDS)

  features|x      Print only feature lines, removing all meta-data,
		  comments, empty lines and fasta from a GFF file.

  fasta_only|q    Print only the fasta sequences from the ##FASTA
		  section from a GFF3 file.

  fasta_no|Q      Remove the ##FASTA section from a GFF3 file.

  fasta_add|r     Add the given fasta file to the GFF3 output in a ##FASTA
		  section.

  meta_only|y     Print only the meta-data lines (pragmas, comments and
		  empty lines) from a GFF file.

  meta_no|Y       Print only the meta-data lines (pragmas, comments and
		  empty lines) from a GFF file.

  meta_add|z      Add the meta-data contained in the given file to the
		  begining of a GFF file.

  pragmas|w       Interactively add GFF3/GVF pragmas to the top of the
		  file.  Use GFF3 or GVF (case insensitive) as an
		  argument to signify which pragma style to
		  create. (Not yet implimented)

  add_ID|v        Add ID attributes where they dont already
		  exist. (Not yet implimented)


--Set Operations--

		  All set operations are based on seqid:start:end
		  unless the set_seq option is set in which case it
		  becomes seqid:start:end:Reference_seq:Variant_seq.
		  The Reference_seq is removed from the Variant_seq
		  list.

  union           The union of all files.  The members that are
		  present in any file.

  intersection    The intersection of all files.  The members that
		  are present in all files.

  l_compliment    The left compliment of the files.  The members
		  found exclusively in the first file but not in any
		  subsequent files.

  s_difference    The symetric difference of the files.  The members
		  found in exactly one file.  Note that the symetric
		  difference should technically give you the members
		  that are present in an odd number of files, but on
		  sets of more than two files that is probably never
		  what you want in this application, so here we give
		  you only the memebers that are present in exactly
		  one file


--GVF Options--

  titv           Calculate transition/transversion ratio.
  gvf_stats      Simple SNV stats on a GVF file.
  effect_stats   Category counts for Variant_effect terms.
  gvf_sets       Calculate counts the pairwise intersection and compliment
		 for all files and the symetric difference for each
		 file. (Not yet implimented)
  fix_gvf        Fix up some common errors in GVF files.  Currently it
		 changes Genotype=(hetero|homo)zygous attributes to
		 Zygosity=(hetero|homo)zygous and uniques the
		 Variant_seq values.


Code References:

All code refs have available to them the current feature as a hash
reference ($f), the attributes of the current feature as a separate
hash reference ($t), any list of values loaded with the ids argument
($i), any values loded with the seqids argument ($si), the sequence of
the current feature ($s) and the current Bio::DB::Fasta object ($d) if
the fasta argument was given.  Changes made by code references can
change any of the values in the variables mentioned above, but those
changes will be discarded before the feature is printed except when
the alter argument is given.  The attributes located in $t are the
same as the ones located in $f->{attributes} but when the alter
command is in effect the values in $t will clobber the
$f->{attributes} before the feature is printed.

The structure of hash references discussed above are:

$f = {feature_id => $feature_id, # Same as the value of the ID attribute
      seqid      => $seqid,
      source     => $source,
      type       => $type,
      start      => $start,
      end        => $end,
      score      => $score,
      strand     => $strand,
      phase      => $phase,
      attributes => $t,
     }

$t = {tag1 => [value1],
      tag2 => [value1, value2],
     }

Examples:

# The --hash_ag code pushes each feature onto a hash keyed by type
# The --code code sorts the stashed feautres by length and shifts off
# longest one which is returned and printed.
gff_tool --hash_ag "push @{$h{$f->{type}}}, $f"          \
	 --code "my @x = sort {($a->{end} - $a->{start}) \
	   <=> ($b->{end} - $b->{start})} @$v;shift @x"  \
	   features.gff3

';

my ($help, $in_place, $out_ext, $FASTA_FILE, $SO_FILE, $IDS_FILE,
    $SEQIDS_FILE, $include, $exclude, $code, $filter, $overlaps,
    $genes, $merge, $blend, $sort, $alter, $hash_ag, $validate,
    $stats, $print_gff, $sequence, $splice_sequence, $fasta_only,
    $fasta_no, $fasta_add, $meta_only, $meta_no, $meta_add, $add_ID,
    $pragmas, $features, $union, $intersection, $l_compliment,
    $s_difference, $titv, $gvf_stats, $effect_stats, $gvf_sets,
    $fix_gvf,);

my $opt_success = GetOptions('in_place|i'      => \$in_place,
			     'out_ext|o=s'     => \$out_ext,
			     'fasta|j=s'       => \$FASTA_FILE,
			     'so_file=s'       => \$SO_FILE,
			     'ids|d=s'	       => \$IDS_FILE,
			     'seqids|d=s'      => \$SEQIDS_FILE,
			     'include|n'       => \$include,
			     'exclude|e'       => \$exclude,
			     'code|c=s'	       => \$code,
			     'filter|t'        => \$filter,
			     'overlaps=s'      => \$overlaps,
			     'genes'           => \$genes,
			     'merge|m'	       => \$merge,
			     'blend|b'	       => \$blend,
			     'sort|s'	       => \$sort,
			     'alter|a'	       => \$alter,
			     'hash_ag|h=s'     => \$hash_ag,
			     'validate|v'      => \$validate,
			     'stats|u'	       => \$stats,
			     'sequence|p'      => \$sequence,
			     'splice_sequence' => \$splice_sequence,
			     'print'           => \$print_gff,
			     'features|x'      => \$features,
			     'fasta_only|r'    => \$fasta_only,
			     'fasta_no|R'      => \$fasta_no,
			     'fasta_add|q=s'   => \$fasta_add,
			     'meta_only|y'     => \$meta_only,
			     'meta_no|Y'       => \$meta_no,
			     'meta_add|z=s'    => \$meta_add,
			     'pragmas|w=s'     => \$pragmas,
			     'add_ID|v'	       => \$add_ID,
			     'union'           => \$union,
			     'intersection'    => \$intersection,
			     'l_compliment'    => \$l_compliment,
			     's_difference'    => \$s_difference,
			     'titv'            => \$titv,
			     'gvf_stats'       => \$gvf_stats,
			     'effect_stats'    => \$effect_stats,
			     'gvf_sets'        => \$gvf_sets,
			     'fix_gvf'         => \$fix_gvf,
			    );

die $usage if $help || ! $opt_success;

die "FATAL : unreadable_file : $FASTA_FILE\n" if ($FASTA_FILE && ! -r $FASTA_FILE);
die "FATAL : unreadable_file : $SO_FILE\n"    if ($SO_FILE    && ! -r $SO_FILE);

my @files = @ARGV;
die "$usage\n\nMust give one or more feature files\n\n" unless (scalar @files || ! -t STDIN);
for my $file (@files) {
 next if $file eq '-';
 die "FATAL : unable_to_open_file : $file\n" if ! -r $file;
}

my $FASTA_DB = parse_fasta($FASTA_FILE) if $FASTA_FILE;
my $IDS      = parse_ids($IDS_FILE)     if $IDS_FILE;
my $SEQIDS   = parse_ids($SEQIDS_FILE)  if $SEQIDS_FILE;

# Move the filter code to the passes_filters sub
filter(\@files, $code)            if $filter;
overlaps(\@files, $overlaps)      if $overlaps;
genes(\@files)                    if $genes;
merge(\@files)		          if $merge;
blend_gff(\@files)		  if $blend;
sort_gff(\@files)		  if $sort;
alter_gff(\@files, $code)         if $alter;
validate(\@files)		  if $validate;
hash_ag(\@files, $hash_ag, $code) if $hash_ag;
stats(\@files)		          if $stats;
sequence(\@files)		  if $sequence;
splice_sequence(\@files)	  if $splice_sequence;
features(\@files)                 if $features;
fasta_only(\@files)		  if $fasta_only;
fasta_no(\@files)		  if $fasta_no;
fasta_add(\@files, $fasta_add)    if $fasta_add;
meta_only(\@files)		  if $meta_only;
#meta_no(\@files)		  if $meta_no;
meta_add(\@files)		  if $meta_add;
add_ID(\@files)		          if $add_ID;
print_gff(\@files)                if $print_gff;
union(\@files)                    if $union;
intersection(\@files)             if $intersection;
l_compliment(\@files)             if $l_compliment;
s_difference(\@files)             if $s_difference;
calc_titv(\@files)                if $titv;
gvf_stats(\@files)                if $gvf_stats;
effect_stats(\@files)              if $effect_stats;
gvf_sets(\@files)                 if $gvf_sets;
#pragma($pragma)	                  if $pragma;

#-----------------------------------------------------------------------------
#-------------------------------- SUBROUTINES --------------------------------
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
#  filter|t        Use the code reference provided with the code
#		  argument described above to filter the features.
#		  Print only those features that return true from the
#		  given code ref.
#  Examples:
#  gff_tool --filter --code 'return 1 if $f->{score} < 100'
#  gff_tool --filter --code 'return 1 unless $t->{Genotype} =~ /homozygous/i'
#-----------------------------------------------------------------------------

sub filter {

    my ($files, $code) = @_;

    for my $file (@files) {
	my $IN  = fh_in($file);
	my $OUT = fh_out($file);
	while (my $f_original = next_feature_hash($IN)) {

	    my $f  = $f_original;
	    my $t  = $f->{attributes};
	    my $i  = $IDS;
	    my $si = $SEQIDS;
	    my $d  = $FASTA_DB;

	    my $return_value = eval $code;
	    die "Fatal Error in code ref: $code\n$@\n" if $@;
	    next unless $return_value;

	    print $OUT to_gff3($f_original);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  overlaps        Print only those features whose start and end coordinates
#                  overlap those given as an argument to this command.
#                  Coordinates are give as seqid:start-end where start
#                  defaults to 1 and end defaults start or 100,000,000,000
#                  if start is also not defined.
#
#  Examples:
#  gff_tool --overlaps chr1:5000-1000
#  gff_tool --overlaps chr1:5000       # same as chr1:5000-5000
#  gff_tool --overlaps chr1            # same as chr1:1-100,000,000,000
#-----------------------------------------------------------------------------

sub overlaps {

    my ($files, $locus) = @_;

    my ($l_seqid, $l_start, $l_end) = split /[:-]/, $locus;
    if (! defined $l_start) {
	$l_start = 1;
	$l_end   = 100000000000;
    }
    $l_end ||= $l_start;

    for my $file (@files) {
	my $IN  = fh_in($file);
	my $OUT = fh_out($file);
	while (my $f = next_feature_hash($IN)) {

	    next if $l_seqid ne $f->{seqid};
	    next unless $l_start <= $f->{end};
	    next unless $l_end   >= $f->{start};

	    print $OUT to_gff3($f);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  genes        Keep only the features commonly associated with gene models
#               from a complex GFF file. (gene mRNA transcript exon CDS
#               start_codon stop_codon three_prime_UTR five_prime_UTR).
#
#  Examples:
#  gff_tool --genes file.gff
#
#-----------------------------------------------------------------------------

sub genes {

  my ($files, $code) = @_;

  my %accept = (gene		=> 1,
		mRNA		=> 1,
		transcript	=> 1,
		exon		=> 1,
		CDS		=> 1,
		start_codon     => 1,
		stop_codon      => 1,
		three_prime_UTR => 1,
		five_prime_UTR  => 1,
	       );
  for my $file (@files) {
    my $IN  = fh_in($file);
    my $OUT = fh_out($file);
    while (my $f = next_feature_hash($IN)) {
      next unless defined $accept{$f->{type}};
      print $OUT to_gff3($f);
    }
  }
  exit;
}

#-----------------------------------------------------------------------------
#  merge|m        Merge takes a feature file(s) and combines the
#		  features.  If gff_tool encounters a second feature
#		  that shares an ID with a previously encountered
#		  feature then both of those features are passed to
#		  the given code reference and the feature that is
#		  returned by the code reference will be saved.  If no
#		  code reference is given, then the first feature
#		  encountered will be saved and a warning issued.
#  Examples:
#
#  Merge two gff files keeping the feature with the greater Variant_freq
#  if two features have the same ID.
#
#  gff_tool --merge --code 'return sort {$a->{Variant_freq} <=> $b->{Variant_freq} ($af, $bf)}'
#-----------------------------------------------------------------------------

sub merge_gff {

    my $files = shift;

    die "gff_tool (merge) not yet implimented!\n";
    exit;
}

#-----------------------------------------------------------------------------
#  blend|b
#
#		  Blend takes a feature file(s) and uniquely blends
#		  the attributes for features that share the same ID.
#		  If two features have the same ID, but conflict in
#		  ways other than the attributes (i.e. seqid, source,
#		  type, start, end, strand, phase values) then blend
#		  will use any code reference provided to the code
#		  argument to resolve which feature to save as
#		  described above for the merge command.  If no code
#		  reference is available then blend will keep the
#		  values from the first feature encountered, then
#		  blend the attributes and issue a warning.
#
#  Examples:
#
#  Blend two GFF files always keeping the last feature encountered if two
#  features share the same ID.
#
#  gff_tool --blend --code 'return $bf'
#-----------------------------------------------------------------------------

sub blend_gff {

    my $files = shift;

    send_message ('WARN',
		  'blend_gff_not_thouroughly_tested',
		  'blend has not been thouroughly tested.  Please help',
		  'us improve gff_tool by carefully evaluating your',
		  'output and contacting us if you find errors.  Thanks',
		  );

    my %features;
    for my $file (@files) {
	my $IN  = fh_in($file);
	my $count = 0;
	while (my $feature = next_feature_hash($IN)) {
	    my $feature_id = $feature->{feature_id};
	    $feature->{count} = $count++;
	    push @{$features{$feature_id}}, $feature;
	}
    }

    my $OUT = fh_out();

    for my $feature_id (sort {$features{$a}[0]{count} <=>
			      $features{$b}[0]{count}} keys %features) {
	my @feature_group = @{$features{$feature_id}};
	my %blend_attributes;
	my %base_feature;
	my %seen_atts;
	if (scalar @feature_group == 1) {
	    %base_feature = %{$feature_group[0]};
	}
	else {
	    for my $feature (@feature_group) {
		my $attributes = $feature->{attributes};
		if (! %base_feature) {
		    @base_feature{qw(feature_id seqid source type start end score strand phase)} =
			@{$feature}{qw(feature_id seqid source type start end score strand phase)};
		}
		for my $tag (keys %{$attributes}) {
		    my @values = @{$attributes->{$tag}};

		    ##########################################################
		    ##########################################################
		    # Temprorary Hack!!! 5/3/10
		    @values = grep {/:\d+$/} @values if $tag eq 'Variant_seq';
		    ##########################################################
		    ##########################################################

		    my @new_values = grep {! $seen_atts{$tag}{$_}++} @values;
		    push @{$blend_attributes{$tag}}, @new_values;
		}
	    }
	    $base_feature{attributes} = \%blend_attributes;
	}
	print $OUT to_gff3(\%base_feature);
    }
    exit;
}

#-----------------------------------------------------------------------------
#  sort|s         Sort the feature file using the code reference given
#		  by the code argument described above.  (Not yet
#		  implimented)
#
#-----------------------------------------------------------------------------

sub sort_gff {

    my ($file, $code) = @_;

    die "gff_tool (sort) not yet implimented!\n";

    $code ||= '{$a->{seqid}';

    my $IN = fh_in($file);
    my $OUT = fh_out($file);
    while (my $f = next_feature_hash($IN)) {

	my $t = $f->{attributes};
	my $i = $IDS;
	my $si = $SEQIDS;
	my $d = $FASTA_DB;

	print $OUT to_gff3($f);
    }
    exit;
}

#-----------------------------------------------------------------------------
#  alter|a        Apply the code reference given by the code argument
#		  described above to each feature.  This is identical
#		  to the filter command described above, but any
#		  alteration made the the feature by the code
#		  reference is kept.
#
#-----------------------------------------------------------------------------

sub alter_gff {

    my ($files, $code) = @_;

    for my $file (@files) {
	my $IN = fh_in($file);
	my $OUT = fh_out($file);
	while (my $f = next_feature_hash($IN)) {

	    my $t = $f->{attributes};
	    my $i = $IDS;
	    my $si = $SEQIDS;
	    my $d = $FASTA_DB;

	    my $return_value = eval $code;
	    die "Fatal Error in code ref: $code\n$@\n" if $@;

	    $f->{attributes} = $t;

	    print $OUT to_gff3($f);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  hash_ag|h
#
#		  The hash_ag argument takes a code reference.  A
#		  second code reference passed to the code argument is
#		  also required.  The function uses the code reference
#		  supplied by the code argument described above to
#		  create a hash (%h).  This may be done, for example,
#		  by pushing all features onto the values of %h keyed
#		  by seqid or type.  After all features have been been
#		  iterated over (and possibly stored) this way,
#		  another loop is run over each key of %h and the code
#		  reference provided to the hash_ag argument is run for each
#		  iteration through that loop.  The variables made
#		  available within this loop are as follows:
#
#		      %h - The hash created as described above.
#		      $k - The current key.
#		      $v - The current value.
#
#		  See the Examples section below.
#-----------------------------------------------------------------------------

sub hash_ag {

    my ($files, $ag_code, $code) = @_;

    my %h;
    for my $file (@{$files}) {
	my $IN = fh_in($file);
	while (my $f = next_feature_hash($IN)) {

	    my $t = $f->{attributes};
	    my $i = $IDS;
	    my $si = $SEQIDS;
	    my $d = $FASTA_DB;

	    my $return_value = eval $ag_code;
	    die "Fatal Error in code ref: $ag_code\n$@\n" if $@;
	}
    }

    my $OUT = fh_out();
    for my $k (keys %h) {

	my $v = $h{$k};

	my @f = eval $code;
	die "Fatal Error in code ref: $code\n$@\n" if $@;
	next unless @f;

	print $OUT to_gff3(\@f);
    }
    exit;
}

#-----------------------------------------------------------------------------
#  validate|v
#
#		  The validate command provides simple validation for
#		  GFF3 and GVF files.  Constraints on values and
#		  attributes are checked as described in the GFF3 and
#		  GVF specification.  If a ##gvf-version pragma is
#		  encountered then GVF constraints will be applied in
#		  addition to GFF3 constraints, otherwise the file
#		  will be validated as GFF3.  Values that are
#		  constrained by the GVF or GFF3 specification to be
#		  SO terms are checked but not SO relationships are
#		  not currently enforced.  A SO.obo file can be passed
#		  as an argument to the validate argument and this
#		  file will be used to validate the SO terms used in
#		  the file.  If no SO file is given, gff_tools will
#		  attempt to access the the current SO file from the
#		  SO website.  If no SO file is available by any of
#		  the above methods, then no validation of SO terms
#		  will be done.  An error report will be printed to
#		  STDOUT.
#-----------------------------------------------------------------------------

sub validate {

  my $files = shift;

  my ($so_data) = parse_so_file();
  #map {$valid_so_terms{$_}++;$valid_so_terms{$so_data->{map}{$_}}++}
  #  keys %{$so_data->{terms}};

    for my $file (@{$files}) {
	warn "Validating: $file\n";
	open(my $IN, '<', $file) or
	    die "FATAL : cant_open_file_for_reading : $file\n";

	my $line_count;
	my %pragmas;
	my %errors;
	my %valid_so_terms;
	my $gff_version;
	my $gvf_version;
	my %feature_ids;
	my %parents;

	my @stack;
	#my $line = <$IN>;
	my ($format_type, $version) = split /\t+/, $line;
	if ($format_type !~ /g[vf]f-version/) {
	    my $error_code = 'missing_required_gff-version_or_gvf-version_pragma';
	    push @{$errors{$error_code}}, [1, $line];
	    warn "WARNING : $error_code : Assuming this file is \#\#gff-version 3 for validation.\n";
	    push @stack, ("\#\#gff-version 3", $line);
	    $line_count--;
	}

      LINE:
	while ($line = shift @stack || <$IN>) {
	    chomp $line;
	    $line_count++;
	    next LINE if $line =~ /^\s*$/;
	    next LINE if $line =~ /^\#[^\#]/;
	    # Features
	    if ($line !~ /^\#/) {
		if ($line !~ /\t/) {
		    my $error_code = 'invalid_feature_line_not_tab_delimited';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		my @columns = split /\t/, $line;
		if (scalar @columns != 9) {
		    my $error_code = 'invalid_feature_line_must_have_nine_columns';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		my ($seqid, $source, $type, $start, $end, $score, $strand,
		    $phase, $att_text) = @columns;
		# Seqid Characters
		if ($seqid =~ /[^a-zA-Z0-9\.:\^\*\$@!\+_\?\-\|]/) {
		    my $error_code = 'invalid_characters_in_seqid_column';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : ($1) $line\n";
		}
		# Seqid and sequence-region
		if ($pragmas{'sequence-region'} && ! $pragmas{'sequence-region'}{$seqid}) {
		    my $error_code = 'invalid_seqid_column_no_associated_sequence_region';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Type
		if ($pragmas{'gvf-version'}) {
		    if (! $valid_so_terms{sequence_alteration}{$type}) {
			my $error_code = 'invalid_type_column_must_be_SO_term_or_ID';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		else {
		    if (! $valid_so_terms{sequence_feature}{$type}) {
			my $error_code = 'invalid_type_column_must_be_SO_term_or_ID';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		# Start
		if ($start !~ /^\d+$/) {
		    my $error_code = 'invalid_start_column_must_be_positive_integer';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		    # Do bounds checking if sequence-region
		}
		# End
		if ($end !~ /^\d+$/) {
		    my $error_code = 'invalid_end_column_must_be_positive_integer';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		    # Do bounds checking if sequence-region
		}
		if ($start > $end) {
		    my $error_code = 'invalid_feature_coordinates_start_is_greater_than_end';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Score
		if ($score ne '.' && $score !~ /^\-?\d+\.?\d*e?\-?\d*$/) {
		    my $error_code = 'invalid_score_column_must_be_real_number';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Strand
		if ($strand  !~ /^[\.\-+\?]$/) {
		    my $error_code = 'invalid_strand_column';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Phase
		if ($phase  !~ /^[\.012]$/) {
		    my $error_code = 'invalid_character_in_phase_column';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Phase && CDS
		if ($type eq 'CDS' && $phase  !~ /^[012]$/) {
		    my $error_code = 'phase_is_required_for_CDS';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Phase ! CDS
		if ($type ne 'CDS' && $phase  =~ /^[012]$/) {
		    my $error_code = 'phase_is_given_for_non_CDS_feature_type';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Attributes
		my %attributes;
		my @pairs = split /;/, $att_text;
	      PAIR:
		for my $pair (@pairs) {
		    if ($pair !~ /(=)/) {
			my $error_code = 'attribute_key_value_pairs_must_be_separated_by_equal_sign';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : ($pair) $line\n";
			next PAIR;
		    }
		    my ($key, $value) = split /=/, $pair;
		    if (! defined $key || ! defined $value) {
			my $error_code = 'attribute_key_value_pairs_must_have_key_and_value';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
			next PAIR;
		    }
		    my @values = split /,/, $value;
		    push @{$attributes{$key}}, @values;
		}
		for my $key (sort keys %attributes) {
		    my @values = @{$attributes{$key}};
		    # ID
		    if ($key eq 'ID') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_ID_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_ids = join ' ', @values;
			    warn "WARNING : $error_code : ($all_ids) $line\n";
			}
			my $id = $values[0];
			if (++$feature_ids{$id} > 1) {
			    my $error_code = 'invalid_ID_attribute_not_unique';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($id) $line\n";
			}
		    }
		    # Name
		    elsif ($key eq 'Name') {
			# No validation on Name values
		    }
		    # Alias
		    elsif ($key eq 'Alias') {
			# No validation on Name values
		    }
		    # Parent
		    elsif ($key eq 'Parent') {
			for my $value (@values) {
			    my $id = $attributes{ID}[0];
			    $parents{$id}{$value}++ if $id;
			}
		    }
		    # Target
		    elsif ($key eq 'Target') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Target_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			if ($value !~ /\S+\s+\d+\s+\d+\s*[\-+]*/) {
			    my $error_code = 'invalid_Target_attribute_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($value) $line\n";
			}
		    }
		    # Gap
		    elsif ($key eq 'Gap') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Gap_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			# TODO: Validate the CIGAR format
		    }
		    # Derives_from
		    elsif ($key eq 'Derives_from') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Derives_from_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			# TODO: Validate the Derives_from relationships
		    }
		    # Note
		    elsif ($key eq 'Note') {
			# No validation on Note value
		    }
		    # Dbxref
		    elsif ($key eq 'Dbxref') {
			for my $value (@values) {
			    my ($db, $ID) = split /:/, $value;
			    # TODO: Validate the Dbxref DB and ID;
			}
		    }
		    # Ontology_term
		    elsif ($key eq 'Ontology_term') {
			# TODO: Validate Ontology_term
		    }
		    # Is_circular
		    elsif ($key eq 'Is_circular') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Is_circular_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			# TODO: Validate Is_circular
		    }
		    # Variant_seq
		    elsif ($key eq 'Variant_seq') {
			for my $value (@values) {
			    # TODO: Validate the length of the Variant_seq
			    if ($type eq 'SNV') {
				if ($value !~ /[ATGC]/i) {
				    my $error_code = 'invalid_Variant_seq_attribute_value_for_SNV';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}
			    }
			    elsif ($type eq 'insertion') {
				if ($value !~ /[ATGCN]+|~/i) {
				    my $error_code = 'invalid_Variant_seq_attribute_value_insertion_indel';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}

			    }
			    elsif ($type eq 'deletion') {
				if ($value !~ /[ATGCN]+|-/i) {
				    my $error_code = 'invalid_Variant_seq_attribute_value_deletion_indel';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}

			    }
			    elsif ($type eq 'indel') {
				if ($value !~ /[ATGCN]+|[-~]/i) {
				    my $error_code = 'invalid_Variant_seq_attribute_value_deletion_indel';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}
			    }
			}
		    }
		    # Reference_seq
		    elsif ($key eq 'Reference_seq') {
			for my $value (@values) {
			    if ($type eq 'SNV') {
				if ($value !~ /[ATGCN]/) {
				    my $error_code = 'invalid_Reference_seq_attribute_value_for_SNV';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}
			    }
			    elsif ($type eq 'insertion') {
				if ($value !~ /[ATGCN]+|-/) {
				    my $error_code = 'invalid_Reference_seq_attribute_value_insertion_indel';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}

			    }
			    elsif ($type eq 'deletion') {
				if ($value !~ /[ATGCN]+|~/) {
				    my $error_code = 'invalid_Reference_seq_attribute_value_deletion_indel';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}

			    }
			    elsif ($type eq 'indel') {
				if ($value !~ /[ATGCN]+|[-~]/) {
				    my $error_code = 'invalid_Reference_seq_attribute_value_deletion_indel';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}

			    }
			}
		    }
		    # Variant_reads
		    elsif ($key eq 'Variant_reads') {
			for my $value (@values) {
			    if ($value !~ /^\d+$/) {
				my $error_code = 'invalid_Variant_reads_attribute_value';
				push @{$errors{$error_code}}, [$line_count, $line];
				warn "WARNING : $error_code : ($value) $line\n";
			    }
			}
		    }
		    # Total_reads
		    elsif ($key eq 'Total_reads') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Total_reads_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			if ($value !~ /^\d+$/) {
			    my $error_code = 'invalid_Total_reads_attribute_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($value) $line\n";
			}
		    }
		    # Genotype
		    elsif ($key eq 'Genotype') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Genotype_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			if ($value !~ /^(hetero|homo|hemi)zygous$/) {
			    my $error_code = 'invalid_Genotype_attribute_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($value) $line\n";
			}
		    }
		    # Variant_freq
		    elsif ($key eq 'Variant_freq') {
			for my $value (@values) {
			    if ($value !~ /^\d+\.?\d*\e?\-?\d*/) {
				my $error_code = 'invalid_Variant_freq_attribute_value';
				push @{$errors{$error_code}}, [$line_count, $line];
				warn "WARNING : $error_code : ($value) $line\n";
			    }
			}
		    }
		    # Variant_effect
		    elsif ($key eq 'Variant_effect') {
			my $value = join ' ', @values;
			my ($sequence_variant, $index, $sequence_feature, @featureIDs) = split /\s+/, $value;
			# TODO: Validate $sequence_variant
			if ($index !~ /^\d+$/ || $index > (scalar @{$attributes{Variant_seq}} - 1)) {
			    my $error_code = 'invalid_Variant_effect_attribute_index_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($index) $line\n";
			}
			if (! $valid_so_terms{sequence_variant}{$sequence_variant}) {
			    my $error_code = 'invalid_Variant_effect_attribute_sequence_variant_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($sequence_variant) $line\n";
			}
			if (! $valid_so_terms{sequence_feature}{$sequence_feature}) {
			    my $error_code = 'invalid_Variant_effect_attribute_sequence_feature_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($sequence_feature) $line\n";
			}
			# TODO: Validate featureIDs
		    }
		    # Variant_copy_number
		    elsif ($key eq 'Variant_copy_number') {
			for my $value (@values) {
			    if ($value !~ /^d+$/) {
				my $error_code = 'invalid_attribute_value';
				push @{$errors{$error_code}}, [$line_count, $line];
				warn "WARNING : $error_code : ($value) $line\n";
			    }
			}
		    }
		    # Reference_copy_number
		    elsif ($key eq 'Reference_copy_number') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Reference_copy_number_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			for my $value (@values) {
			    if ($value !~ /^\d+$/) {
				my $error_code = 'invalid_Reference_copy_number_attribute_value';
				push @{$errors{$error_code}}, [$line_count, $line];
				warn "WARNING : $error_code : ($value) $line\n";
			    }
			}
		    }
		    # Start_range
		    elsif ($key eq 'Start_range') {
			if (scalar @values != 2) {
			    my $error_code = 'invalid_Start_range_attribute_must_have_2_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ',', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			if ($values[0] =~ /^\d+$/ && $values[0] > $start) {
			    my $error_code = 'invalid_Start_range_attribute_values_must_contain_start';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ',', @values;
			    warn "WARNING : $error_code : ($all_values, $start) $line\n";
			}
			if ($values[1] =~ /^\d+$/ && $values[1] < $start) {
			    my $error_code = 'invalid_Start_range_attribute_values_must_contain_start';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ',', @values;
			    warn "WARNING : $error_code : ($all_values, $start) $line\n";
			}
			for my $value (@values) {
			    if ($value ne '.' && $value !~ /^\d+$/) {
				my $error_code = 'invalid_Start_range_attribute_value';
				push @{$errors{$error_code}}, [$line_count, $line];
				warn "WARNING : $error_code : ($value) $line\n";
			    }
			}
		    }
		    # End_range
		    elsif ($key eq 'End_range') {
			if (scalar @values != 2) {
			    my $error_code = 'invalid_Etart_range_attribute_must_have_2_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ',', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			if ($values[0] =~ /^\d+$/ && $values[0] > $end) {
			    my $error_code = 'invalid_End_range_attribute_values_must_contain_end';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ',', @values;
			    warn "WARNING : $error_code : ($all_values, $end) $line\n";
			}
			if ($values[1] =~ /^\d+$/ && $values[1] < $end) {
			    my $error_code = 'invalid_End_range_attribute_values_must_contain_end';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ',', @values;
			    warn "WARNING : $error_code : ($all_values, $end) $line\n";
			}
			for my $value (@values) {
			    if ($value ne '.' && $value !~ /^\d+$/) {
				my $error_code = 'invalid_End_range_attribute_value';
				push @{$errors{$error_code}}, [$line_count, $line];
				warn "WARNING : $error_code : ($value) $line\n";
			    }
			}
		    }
		    # Phased
		    elsif ($key eq 'Phased') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Phased_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			# TODO: Validate the Phased attribute
		    }
		}
	    }
	    # Pragmas
	    else {
		##gff-version
		if ($line =~ /^\#\#gff-version/) {
		    chomp $line;
		    $line_count++;
		    my $seen = {};
		    my $children = {};
		    my %relationships = (is_a    => 1,
					 part_of => 1,
					 );
		    # Get valid sequence_feature terms
		    no warnings;
		    ($seen, $children) = get_so_children($so_data, 'SO:0000110', \%relationships, $seen, $children);
		    %{$valid_so_terms{sequence_feature}} = ('SO:0000110' => 1);
		    use warnings;
		    map {$valid_so_terms{sequence_feature}{$_}++} keys %{$children};
		    map {$valid_so_terms{sequence_feature}{$_}++} @{$so_data->{map}}{keys %{$valid_so_terms{sequence_feature}}};
		    if ($line =~ /^\#\#gff-version\s+(\d+\.?\d*)/) {
			$pragmas{'gff-version'} = $1;
		    }
		    else {
			my $error_code = 'invalid_gff-version_pragma_value';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##gvf-version
		elsif ($line =~ /^\#\#gvf-version/) {
		    $line_count++;
		    my $seen = {};
		    my $children = {};
		    my %relationships = (is_a    => 1,
					 part_of => 1,
					 );
		    # Get valid sequence_alteration terms
		    no warnings;
		    ($seen, $children) = get_so_children($so_data, 'SO:0001059', \%relationships, $seen, $children);
		    use warnings;
		    %{$valid_so_terms{sequence_alteration}} = ('SO:0001059' => 1,
							       'SO:0000730' => 1
							       );
		    map {$valid_so_terms{sequence_alteration}{$_}++} keys %{$children};
		    map {$valid_so_terms{sequence_alteration}{$_}++} @{$so_data->{map}}{keys %{$valid_so_terms{sequence_alteration}}};

		    # Get valid sequence_variant terms
		    $seen = {};
		    $children = {};
		    no warnings;
		    ($seen, $children) = get_so_children($so_data, 'SO:0001060', \%relationships, $seen, $children);
		    use warnings;
		    %{$valid_so_terms{sequence_variant}} = ('SO:0001060' => 1);
		    map {$valid_so_terms{sequence_variant}{$_}++} keys %{$children};
		    map {$valid_so_terms{sequence_variant}{$_}++} @{$so_data->{map}}{keys %{$valid_so_terms{sequence_variant}}};

		    if ($line =~ /^\#\#gvf-version\s+(\d+\.?\d*)/) {
			$pragmas{'gvf-version'} = $1;
		    }
		    else {
			my $error_code = 'invalid_gvf-version_pragma_value';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##feature-ontology
		elsif ($line =~ /^\#\#feature-ontology/) {
		    if ($line =~ /^\#\#(feature-ontology)\s+(\S+)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
			# TODO: test_uri($pragma_value);
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##attribute-ontology
		elsif ($line =~ /^\#\#attribute-ontology/) {
		    if ($line =~ /^\#\#(attribute-ontology)\s+(\S+)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
			#TODO: test_uri($pragma_value);
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##source-ontology
		elsif ($line =~ /^\#\#source-ontology/) {
		    if ($line =~ /^\#\#(source-ontology)\s+(\S+)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
			#TODO: test_uri($pragma_value);
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##species
		elsif ($line =~ /^\#\#species/) {
		    if ($line =~ /^\#\#(species)\s+(\S+)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
			# TODO: test_uri($pragma_value);
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##genome-build
		elsif ($line =~ /^\#\#genome-build/) {
		    if ($line =~ /^\#\#(genome-build)\s+(\S+)\s+(\S+)/) {
			my $pragma_key = $1;
			my $source     = $2;
			my $build_name = $3;
			$pragmas{$pragma_key}{$source} = $build_name;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##sequence-region
		elsif ($line =~ /^\#\#sequence-region/) {
		    if ($line =~ /^\#\#(sequence-region)\s+(\S+)\s+(\d+)\s+(\d+)/) {
			my $pragma_key = $1;
			my $seqid      = $2;
			my $start      = $3;
			my $end        = $4;
			if (! $seqid || ! $start || ! $end) {
			    my $error_code = 'missing_sequence-region_pragma_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : $line\n";
			}
			elsif ($start !~ /^\d+$/ || $end !~ /^\d+$/) {
			    my $error_code = 'invalid_sequence-region_pragma_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : $line\n";
			}
			else {
			    $pragmas{$pragma_key}{$seqid} = [$start, $end];
			}
		    }
		}
		##file-date
		elsif ($line =~ /^\#\#file-date /) {
		    if ($line =~ /^\#\#(file-date)\s+(20[1-9][0-9]-\d\d-\d\d)/) {
			my $pragma_key = $1;
			my $date       = $2;
			$pragmas{$pragma_key} = $date;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##file-version
		elsif ($line =~ /^\#\#file-version /) {
		    if ($line =~ /^\#\#(file-version)\s+(.*?)/) {
			my $pragma_key = $1;
			my $version    = $2;
			$pragmas{$pragma_key} = $version;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##individual-id
		elsif ($line =~ /^\#\#individual-id/) {
		    if ($line =~ /^\#\#(individual-id)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##score-method
		elsif ($line =~ /^\#\#score-method/) {
		    if ($line =~ /^\#\#(score-method)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##source-method
		elsif ($line =~ /^\#\#source-method/) {
		    if ($line =~ /^\#\#(source-method)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##attribute-method
		elsif ($line =~ /^\#\#attribute-method/) {
		    if ($line =~ /^\#\#(attribute-method)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##technology-platform
		elsif ($line =~ /^\#\#technology-platform/) {
		    if ($line =~ /^\#\#(technology-platform)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##data-source
		elsif ($line =~ /^\#\#data-source/) {
		    if ($line =~ /^\#\#(data-source)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##phenotype-description
		elsif ($line =~ /^\#\#phenotype-description/) {
		    if ($line =~ /^\#\#(phenotype-description)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##phased-genotypes
		elsif ($line =~ /^\#\#phased-genotypes/) {
		    if ($line =~ /^\#\#(phased-genotypes)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		###
		elsif ($line =~ /^\#\#\#$/) {
		  # Skip ### - there's no way to further validate it.
		}
		# All other pragmas
		else {
		    $line =~ /^\#\#(\S+)\s*(.*)/;
		    my $pragma_key   = $1;
		    my $pragma_value = $2;
		    my $error_code = 'non_standard_pragma';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		    push @{$pragmas{$pragma_key}}, $pragma_value;
		}
	    }
	}

	close $IN;
	print "\n\n";
	print "Error Summary for $file\n";
	print '#' x 80;
	print "\n";
	if (scalar keys %errors) {
	    print "Error Code\tCount\n";
	    for my $error_code (keys %errors) {
		print "$error_code\t" . scalar @{$errors{$error_code}} . "\n";
	    }
	}
	else {
	    print "No Errors found in this file\n";
	}
	print '#' x 80;
	print "\n\n";
    }
}

#-----------------------------------------------------------------------------
#  stats|u	  Return simple summary statistics for the given file.
#		  (Not yet implimented)
#-----------------------------------------------------------------------------

sub stats {

    die "gff_tool (stats) not yet implimented!\n";
    exit;
}


#-----------------------------------------------------------------------------
#  sequence|p     Print a fasta sequence for each feature instead of
#		  the feature. Requires the fasta argument.
#-----------------------------------------------------------------------------

sub sequence {

  my $files = shift;

  for my $file (@{$files}) {
    my $IN  = fh_in($file);
    my $OUT = fh_out($file);
    while (my $f = next_feature_hash($IN)) {

      my ($seqid, $start, $end) = @{$f}{qw(seqid start end)};

      my $header = $f->{attributes}{ID}[0];
      my $seq = $FASTA_DB->seq($seqid, $start, $end);

      $seq =~ s/(.{50})/$1\n/g;

      print ">$header\n$seq\n";
    }
  }
  exit;
}

#-----------------------------------------------------------------------------
#  splice_sequence Print the mature fasta sequence for spliced
#  features (exons, CDS)
#-----------------------------------------------------------------------------

sub splice_sequence {

  my $files = shift;

  for my $file (@{$files}) {
    my $IN  = fh_in($file);
    my $OUT = fh_out($file);

    my %spliced_seq;
    while (my $f = next_feature_hash($IN)) {

      my $a = $f->{attributes};

      if (exists $a->{Parent}) {
	my @parents = @{$a->{Parent}};

	my ($seqid, $start, $end, $strand) = @{$f}{qw(seqid start end strand)};


	for my $parent (@parents) {
	  push @{$spliced_seq{$parent}{coords}{$seqid}}, [$start, $end];
	  $spliced_seq{$parent}{strand} = $strand;
	}
      }
    }

    for my $id (keys %spliced_seq) {
      my $strand = $spliced_seq{$id}{strand};
      for my $seqid (keys %{$spliced_seq{$id}{coords}}) {
	my @coords;
	if ($strand eq '-') {
	  @coords = sort {$b->[0] <=> $a->[0]} @{$spliced_seq{$id}{coords}{$seqid}};
	}
	else {
	  @coords = sort {$a->[1] <=> $b->[1]} @{$spliced_seq{$id}{coords}{$seqid}};
	}

	my $spliced_seq;
	for my $pair (@coords) {
	  @{$pair} = reverse @{$pair} if $strand eq '-';
	  my $seq = $FASTA_DB->seq($seqid, $pair->[0], $pair->[1]);
	  $spliced_seq .= $seq;
	}
	$spliced_seq =~ s/(.{50})/$1\n/g;
	my $header = "$id";
	print ">$header\n$spliced_seq\n";
	print '';
      }
    }
  }
  exit;
}

#-----------------------------------------------------------------------------
#  fasta_add|q    Add a fasta file to the GFF3 output in a ##FASTA
#		  section.
#-----------------------------------------------------------------------------

sub fasta_add {

    my ($files, $fasta_add) = @_;
    send_message ('WARN',
		  'fasta_add_not_fully_tested',
		  'fasta_add) function is written, but untested'
		  );

    die "Can't open $fasta_add for reading\n" unless -r $fasta_add;
    for my $file (@{$files}) {
	my ($fasta_section) = `grep -P '^##FASTA' $file`;
	open(my $OUT, '<<', $file) or die "Can't open $file for appending\n";
	print $OUT "\n## FASTA\n"  unless $fasta_section;
	print $OUT `cat $fasta_add`;
	close $OUT;
    }
    exit;
}

#-----------------------------------------------------------------------------
#  fasta_only|r   Print only the fasta section from a GFF3 file
#-----------------------------------------------------------------------------

sub fasta_only {

    die "\n\ngff_tool (strip_fasta) function is written, but untested\n\n";

    for my $file (@files) {
	unlink $file or die "Can't unlink $file\n$!\n";
	open (my $OUT, '>', $file) or die "Can't open $file for writing :\n$!\n";
	open (my $IN, '<', $file) or die "Can't open $file for reading :\n$!\n";
	my $fasta_flag;
	while (<$IN>) {
	    $fasta_flag++ if /^\#\#\s*FASTA/;
	    next unless $fasta_flag;
	    print $OUT, $_;
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  fasta_no|R Print the pragmas, comments and features, but not the fasta
#             section from a GFF3 file.
#-----------------------------------------------------------------------------

sub fasta_no {

    die "\n\ngff_tool (fasta_no) function is written, but untested\n\n";

    for my $file (@files) {
	unlink $file or die "Can't unlink $file\n$!\n";
	open (my $OUT, '>', $file) or die "Can't open $file for writing :\n$!\n";
	open (my $IN, '<', $file) or die "Can't open $file for reading :\n$!\n";
	while (<$IN>) {
	    last if /^\#\#\s*FASTA/;
	    print $OUT, $_;
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  add_ID|v        Add ID attributes where they dont already
#		  exist. (Not yet implimented)
#-----------------------------------------------------------------------------

sub add_ID {

    die "gff_tool (add_ID) not yet implimented!\n";
    exit;
}

#-----------------------------------------------------------------------------
#  pragmas|w  Interactively add GFF3/GVF pragmas to the top of the
#		  file.  Use GFF3 or GVF (case insensitive) as an
#		  argument to signify which pragma style to
#		  create. (Not yet implimented)
#-----------------------------------------------------------------------------

sub pragmas {

    die "gff_tool (gff_pragmas) not yet implimented!\n";
    exit;
}

#-----------------------------------------------------------------------------
#  headers_only|y Print only the headers lines (pragmas, comments and
#		  whitespace up to the first feature line) from a GFF
#		  file.
#-----------------------------------------------------------------------------

sub headers_only {

    for my $file (@files) {
	open (my $IN, '<', $file) or die "Can't open $file for reading :\n$!\n";
	my $OUT = fh_out($file);
	while (<$IN>) {
	    last if /^\s*\#\#\s*FASTA/;
	    next unless /^\s*\#/ || /^\s*$/;
	    print $OUT $_;
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  headers_no|Y   Print everything except headers lines (pragmas, comments and
#		  whitespace up to the first feature line) from a GFF
#		  file.
#-----------------------------------------------------------------------------

sub headers_no {

    for my $file (@files) {
	open (my $IN, '<', $file) or die "Can't open $file for reading :\n$!\n";
	my $OUT = fh_out($file);
	while (<$IN>) {
	    last if /^\s*\#\#\s*FASTA/;
	    next if /^\s*\#/ || /^\s*$/;
	    print $OUT $_;
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  header_add|z    Add a header file to the begining of a GFF file.
#-----------------------------------------------------------------------------

sub meta_add {

    for my $file (@files) {
	open (my $IN, '<', $file) or die "Can't open $file for reading:\n$!\n";
	open (my $HEAD, '<', $meta_add) or die "Can't open $meta_add for reading:\n$!\n";
	my $OUT = fh_out($file);
	print $OUT (<$HEAD>);
	print $OUT (<$IN>);
    }
    exit;
}

#-----------------------------------------------------------------------------
#  features|x     Print only feature lines, removing all headers, comments,
#		  empty lines and fasta from a GFF file.
#-----------------------------------------------------------------------------

sub features {

    for my $file (@files) {
	open (my $IN, '<', $file) or die "Can't open $file for reading:\n$!\n";
	my $OUT = fh_out($file);
	while (<$IN>) {
	    last if /^\s*\#\#\s*FASTA/;
	    next if /^\s*\#/ || /^\s*$/;
	    print $OUT $_;
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  union           The union of all files.
#-----------------------------------------------------------------------------

sub union {

    my $files = shift;
    my %union;
    for my $file (@{$files}) {
	my $IN = fh_in($file);
	while (my $f = next_feature_hash($IN)) {
	    my $loc_id  = join ':', @{$f}{qw(seqid start end)};
	    # if ($set_seq) {
	    #	my $a = $f->{attributes};
	    #	my $ref_seq = $a->{Reference_seq}[0];
	    #	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	    #	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
	    # }
	    $union{$loc_id} ||= $f;
	}
    }
    my $OUT = fh_out();
    for my $loc_id (sort keys %union) {
	my $f = $union{$loc_id};
	print $OUT to_gff3($f);
    }
    exit;
}

#-----------------------------------------------------------------------------
#  intersection    The intersection of all files.
#-----------------------------------------------------------------------------

sub intersection {

    my $files = shift;
    my (%inter_count, %inter_stash);
    my $file_count = 1;
    my $file = shift @{$files};
    my $IN = fh_in($file);
    while (my $f = next_feature_hash($IN)) {
	my $loc_id  = join ':', @{$f}{qw(seqid start end)};
	# if ($set_seq) {
	#	my $a = $f->{attributes};
	#	my $ref_seq = $a->{Reference_seq}[0];
	#	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	#	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
	# }
	$inter_stash{$loc_id} ||= $f;
	$inter_count{$loc_id}++;
    }
    for my $file (@files) {
	my $IN = fh_in($file);
	$file_count++;
	while (my $f = next_feature_hash($IN)) {
	    my $loc_id  = join ':', @{$f}{qw(seqid start end)};
	    # if ($set_seq) {
	    #	my $a = $f->{attributes};
	    #	my $ref_seq = $a->{Reference_seq}[0];
	    #	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	    #	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
	    # }
	    $inter_count{$loc_id}++;
	}
    }
    my $OUT = fh_out();
    for my $loc_id (sort keys %inter_stash) {
	if ($inter_count{$loc_id} == $file_count) {
	    my $f = $inter_stash{$loc_id};
	    print $OUT to_gff3($f);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  l_compliment    The members found exclusively in the first file
#                  but not in any subsequent files.
#-----------------------------------------------------------------------------

sub l_compliment {
    my $files = shift;
    my (%comp_stash, %comp_count);
    my %others;
    my $file = shift @{$files};
    my $IN = fh_in($file);
    while (my $f = next_feature_hash($IN)) {
	my $loc_id  = join ':', @{$f}{qw(seqid start end)};
	# if ($set_seq) {
	#   my $a = $f->{attributes};
	#   my $ref_seq = $a->{Reference_seq}[0];
	#   my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	#   $loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
	# }
	$comp_stash{$loc_id} = $f;
	$comp_count{$loc_id}++;
    }
    for my $file (@files) {
	my $IN = fh_in($file);
	while (my $f = next_feature_hash($IN)) {
	    my $loc_id  = join ':', @{$f}{qw(seqid start end)};
	    # if ($set_seq) {
	    #	my $a = $f->{attributes};
	    #	my $ref_seq = $a->{Reference_seq}[0];
	    #	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	    #	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
	    # }
	    $comp_count{$loc_id}++;
	}
    }
    my $OUT = fh_out();
    for my $loc_id (sort keys %comp_stash) {
	if ($comp_count{$loc_id} == 1) {
	    next unless exists $comp_stash{$loc_id};
	    my $f = $comp_stash{$loc_id};
	    print $OUT to_gff3($f);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  s_difference    The members found in exactly one file.
#-----------------------------------------------------------------------------

sub s_difference {
    my $files = shift;
    my (%diff_count, %diff_stash);
    for my $file (@files) {
	my $IN = fh_in($file);
	while (my $f = next_feature_hash($IN)) {
	    my $loc_id  = join ':', @{$f}{qw(seqid start end)};
	    # if ($set_seq) {
	    #	my $a = $f->{attributes};
	    #	my $ref_seq = $a->{Reference_seq}[0];
	    #	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	    #	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
	    # }
	    $diff_stash{$loc_id} ||= $f;
	    $diff_count{$loc_id}++;
	}
    }
    my $OUT = fh_out();
    for my $loc_id (sort keys %diff_stash) {
	if ($diff_count{$loc_id} == 1) {
	    my $f = $diff_stash{$loc_id};
	    print $OUT to_gff3($f);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  gvf_sets       Calculate the pairwise intersection and compliment
#                 for all files and the symetric difference for each
#                 file.
#-----------------------------------------------------------------------------

sub gvf_sets {

#     my $files = shift;
#     my (%diff, %comp, %union);
#     for my $file1 (@files) {
#	my $IN = fh_in($file1);
#	while (my $f = next_feature_hash($IN)) {
#	    my $loc_id  = join ':', @{$f}{qw(seqid start end)};
#	    # if ($set_seq) {
#	    #	my $a = $f->{attributes};
#	    #	my $ref_seq = $a->{Reference_seq}[0];
#	    #	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
#	    #	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
#	    # }
#	    $diff_stash{$loc_id} ||= $f;
#	    $diff_count{$loc_id}++;
#	}
#	for my $file2 (@files) {
#	    my $IN = fh_in($file2);
#	    while (my $f = next_feature_hash($IN)) {
#     }
#     my $OUT = fh_out();
#     for my $loc_id (sort keys %diff_stash) {
#	if ($diff_count{$loc_id} == 1) {
#	    my $f = $diff_stash{$loc_id};
#	    print $OUT to_gff3($f);
#	}
#     }
  exit;
}

#-----------------------------------------------------------------------------
#  titv           Calculate transition/transversion ratio.
#-----------------------------------------------------------------------------

sub calc_titv {

    my $files = shift;
    my ($ti, $tv);

    for my $file (@files) {
	my $IN = fh_in($file);
	print "$file\t";
	($ti, $tv) = ();
	while (my $f = next_feature_hash($IN)) {
	    my $a = $f->{attributes};
	    my $ref_seq = $a->{Reference_seq}[0];
	    my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	    if ($ref_seq eq 'A') {
		if ($var_seq eq 'C') {
		    $tv++;
		}
		elsif ($var_seq eq 'G') {
		    $ti++;
		}
		elsif ($var_seq eq 'T') {
		    $tv++;
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    elsif ($ref_seq eq 'C') {
		if ($var_seq eq 'A') {
		    $tv++;
		}
		elsif ($var_seq eq 'G') {
		    $tv++;
		}
		elsif ($var_seq eq 'T') {
		    $ti++;
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    elsif ($ref_seq eq 'G') {
		if ($var_seq eq 'A') {
		    $ti++;
		}
		elsif ($var_seq eq 'C') {
		    $tv++;
		}
		elsif ($var_seq eq 'T') {
		    $tv++;
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    elsif ($ref_seq eq 'T') {
		if ($var_seq eq 'A') {
		    $tv++;
		}
		elsif ($var_seq eq 'C') {
		    $ti++;
		}
		elsif ($var_seq eq 'G') {
		    $tv++;
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    else {
		my $line = to_gff3($f);
		warn "WARNING : reference_seq_not_handled: $line";
	    }
	}
	my $ti_tv_ratio = $tv ? $ti/$tv : 'NaN';
	print join "\t", ($ti, $tv, $ti_tv_ratio);
	print "\n";
    }
    exit;
}


#-----------------------------------------------------------------------------
#  gvf_stats           Simple SNV stats on a GVF file.
#-----------------------------------------------------------------------------

sub gvf_stats {

    my $files = shift;
    my ($count, $ti, $tv, $het, $hom);

    $meta_no = 1;
    $| = 1;

    print join "\t", qw(File Count Het Hom Het/Hom Pct_Het Ti Tv Ti/Tv);
    print "\n";
    for my $file (@files) {
	my $IN = fh_in($file);
	($count, $ti, $tv, $het, $hom) = ();
	while (my $f = next_feature_hash($IN)) {
	    next unless $f->{type} eq 'SNV';
	    my $a = $f->{attributes};
	    next unless ref $a->{Variant_seq} eq 'ARRAY';
	    next unless ref $a->{Reference_seq} eq 'ARRAY';
	    $count++;
	    if (scalar @{$a->{Variant_seq}} > 1) {
		$het++;
	    }
	    else {
		$hom++;
	    }
	    my $ref_seq = $a->{Reference_seq}[0];
	    my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	    if ($ref_seq eq 'A') {
		if ($var_seq eq 'C') {
		    $tv++;
		}
		elsif ($var_seq eq 'G') {
		    $ti++;
		}
		elsif ($var_seq eq 'T') {
		    $tv++;
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    elsif ($ref_seq eq 'C') {
		if ($var_seq eq 'A') {
		    $tv++;
		}
		elsif ($var_seq eq 'G') {
		    $tv++;
		}
		elsif ($var_seq eq 'T') {
		    $ti++;
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    elsif ($ref_seq eq 'G') {
		if ($var_seq eq 'A') {
		    $ti++;
		}
		elsif ($var_seq eq 'C') {
		    $tv++;
		}
		elsif ($var_seq eq 'T') {
		    $tv++;
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    elsif ($ref_seq eq 'T') {
		if ($var_seq eq 'A') {
		    $tv++;
		}
		elsif ($var_seq eq 'C') {
		    $ti++;
		}
		elsif ($var_seq eq 'G') {
		    $tv++;
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    else {
		my $line = to_gff3($f);
		warn "WARNING : reference_seq_not_handled: $line";
	    }
	}
	$hom = 0 if ! defined $hom;
	$het = 0 if ! defined $het;
	my $het_hom_ratio = $hom ? $het/$hom : 'NaN';
	my $ti_tv_ratio   = $tv  ? $ti/$tv   : 'NaN';
	print join "\t", ($file, $count, $het, $hom, $het_hom_ratio, $het/($het + $hom)*100, $ti, $tv, $ti_tv_ratio);
	print "\n";
    }
    exit;
}

#-----------------------------------------------------------------------------
# effect_stats   Category counts for Variant_effect terms.
#-----------------------------------------------------------------------------

sub effect_stats {

    my $files = shift;
    my ($count, $ti, $tv, $het, $hom);

    print join "\t", ('Term', @{$files});
    print "\n";
    my (%files, %terms, %term_total);
    for my $file (@files) {
	$files{$file}++;
	my $IN = fh_in($file);
	($count, $ti, $tv, $het, $hom) = ();
	while (my $f = next_feature_hash($IN)) {
	    my $effects = $f->{attributes}{Variant_effect} || [];
	    for my $term (@{$effects}) {
		$term =~ s/(\S+).*/$1/;
		$terms{$term}{$file}++;
		$term_total{$term}++;
	    }
	}
    }
    for my $term (sort {$term_total{$b} <=> $term_total{$a}} keys %terms) {
	print "$term";
	for my $file (sort keys %files) {
	    my $count = $terms{$term}{$file} || 0;
	    print "\t$count";
	}
	print "\n";
    }
    exit;
}

#-----------------------------------------------------------------------------

sub parse_ids {

  my $file = shift;

  my %ids;
  if ($file && ! -r $file) {
    warn "WARN : assuming_id_name : Assuming $file is an ID";
    $ids{$file}++;
    return \%ids;
  }

  open (my $IN, "<", $file) or
    die "Can't open $file for reading: $!\n";

  %ids = map {chomp;$_ => 1} (<$IN>);

  return \%ids;
}


#-----------------------------------------------------------------------------

sub parse_fasta {

  my $path = shift;

  require Bio::DB::Fasta;

  my $db = Bio::DB::Fasta->new($path);

  return $db;
}

#-----------------------------------------------------------------------------

sub get_sequence_code_ref {

  my ($feature, $db) = @_;

  return
    sub {
      my ($seqid, $start, $end) = @{$feature}{qw(seqid start end)};
      return $db->seq($seqid, $start, $end);
    }
  }

#-----------------------------------------------------------------------------

sub fails_filters {

	my $feature = shift;

	my $fail;

	#Move the filter sub code here


	if ($IDS && %{$IDS}) {
	    $fail++ if ($include && ! $IDS->{$feature->{feature_id}});
	    $fail++ if ($exclude &&   $IDS->{$feature->{feature_id}});
	}
	if ($SEQIDS && %{$SEQIDS}) {
	    $fail++ if ($include && ! $SEQIDS->{$feature->{seqid}});
	    $fail++ if ($exclude &&   $SEQIDS->{$feature->{seqid}});
	}
	return $fail;
}

#-----------------------------------------------------------------------------

sub print_gff {

    my $files = shift;

    for my $file (@files) {
	my $IN = fh_in($file);
	my $OUT = fh_out($file);
	while (my $f = next_feature_hash($IN)) {
	    next if fails_filters($f);
	    print $OUT to_gff3($f);
	}
    }
}

#-----------------------------------------------------------------------------

sub fh_in {

    my $file = shift;

    my $IN;
    if ($file eq '-') {
	open ($IN, "<&=STDIN")   or die "Can't open STDIN:\n$!\n";
    }
    elsif ($file) {
	open ($IN, "<", $file)   or die "Can't open $file for reading: $!\n";
    }
    else {
	return undef;
    }

    return $IN;
}

#-----------------------------------------------------------------------------

sub fh_out {

    my $file = shift;

    my $OUT;
    if ($in_place && $file) {
	unlink $file;
	open ($OUT, ">", $file)   or die "Can't open $file for writing:\n$!\n";
    }
    elsif ($out_ext && $file) {
	$file .= $out_ext;
	open ($OUT, ">", $file)   or die "Can't open $file for writing:\n$!\n";
    }
    else {
	open ($OUT, ">&=STDOUT") or die "Can't open STDOUT for writing:\n$!\n";
    }
    return $OUT;
}

#-----------------------------------------------------------------------------

sub next_feature_hash {

    my $fh = shift;

    my $line = <$fh>;
    return undef unless defined $line;

    until ($line !~ /^(\#.*|\s+)$/) {
	handle_header_line($line, $fh);
	$line = <$fh>;
	return undef unless defined $line;
    }
    chomp $line;

    my %feature;
    @feature{qw(seqid source type start end score strand phase attributes)} =
	split /\t/, $line;

    my %attributes;
    my $att_text = $feature{attributes};
    my @pairs = split /;/, $att_text;
    if (! defined $att_text) {
	warn "Warn : no_attributes : ($att_text) $line\n" unless defined $att_text;
    }
    for my $pair (@pairs) {
	my ($key, $value_text) = split /=/, $pair;
	if (! defined $key || ! defined $value_text) {
	    warn "Warn : attribute_with_no_key : ($pair) $line\n"
		unless defined $key;
	    warn "Warn : attribute_with_no_value : ($pair) $line\n"
		unless defined $value_text;
	    next;
	}
	my @values = split ',', $value_text;
	push @{$attributes{$key}}, @values;
    }
    $feature{feature_id} = $attributes{ID}[0];
    $feature{attributes} = \%attributes;
    return wantarray ? %feature : \%feature;
}

#-----------------------------------------------------------------------------

sub handle_header_line {

    my ($line, $fh) = @_;

    if ($line =~ /^\#\#FASTA/) {
	handle_fasta($fh);
	return undef;
    }

    return undef if $meta_no;
    return undef if $line =~ /^\#\#\#\s*$/;

    if ($line =~ /^\#\#sequence-region\s(\S+)/) {
	if ($include && %{$SEQIDS} ) {
	    return unless $SEQIDS->{$1};
	}
	elsif ($exclude && %{$SEQIDS}) {
	    return if $SEQIDS->{$1};
	}
    }
    print $line;
}

#-----------------------------------------------------------------------------

sub handle_fasta {

    my $fh = shift;

    if ($fasta_no) {
      my $line = <$fh>;
      print STDERR "WARN : skipping_fasta_sequence : $line\n";
      while (my $line = <$fh>) {
	next unless $line;
	chomp $line;
	if ($line =~ /^>/) {
	  print STDERR "WARN : skipping_fasta_sequence : $line\n";
	  next;
	}
	if ($line !~ /^[ATGCN]*$/i) {
	  print STDERR "FATAL : non_standard_fasta_line : $line\n";
	}
      }
      return undef;
    }

    require Bio::SeqIO;

    my $seq_io  = Bio::SeqIO->new(-fh => $fh,
				  -format => 'Fasta');

    print "\n##FASTA\n";
    while (my $seq_obj = $seq_io->next_seq) {
	my $id = $seq_obj->display_id;
	if ($include && scalar keys %{$SEQIDS} ) {
	    next unless $SEQIDS->{$id};
	}
	elsif ($exclude && scalar keys %{$SEQIDS}) {
	    next if $SEQIDS->{$id};
	}
	my $header = $id . " " . $seq_obj->description;
	my $seq = $seq_obj->seq;
	$seq =~ s/(.{60})/$1\n/g;
	print ">$header\n$seq\n";
    }
    close $fh;
}

#-----------------------------------------------------------------------------

sub to_gff3 {

    my $features = shift;

    my %ATTRB_ORDER = (ID                    => 1,
		       Name                  => 2,
		       Alias                 => 3,
		       Parent                => 4,
		       Target                => 5,
		       Gap                   => 6,
		       Derives_from          => 7,
		       Note                  => 8,
		       Dbxref                => 9,
		       Ontology_term         => 10,
		       Variant_seq           => 11,
		       Reference_seq         => 12,
		       Variant_reads         => 13,
		       Total_reads	     => 14,
		       Genotype	             => 15,
		       Variant_effect        => 16,
		       Variant_copy_number   => 17,
		       Reference_copy_number => 18,
		       );

    $features = [$features] unless ref $features eq 'ARRAY';

    my $gff3_text;
    for my $feature (@{$features}) {
	my $attribute_text;
	for my $key (sort {($ATTRB_ORDER{$a} || 99) <=> ($ATTRB_ORDER{$b} || 99) ||
			       $a cmp $b}
		     keys %{$feature->{attributes}}) {
	    my $value_text = join ',', @{$feature->{attributes}{$key}};
	    $attribute_text .= "$key=$value_text;";
	}

	my $feature_text = join "\t", ($feature->{seqid},
				    $feature->{source},
				    $feature->{type},
				    $feature->{start},
				    $feature->{end},
				    $feature->{score},
				    $feature->{strand},
				    $feature->{phase},
				    $attribute_text,
				    );

	$gff3_text .= "$feature_text\n";
    }
    return $gff3_text;
}

#-----------------------------------------------------------------------------

sub parse_so_file {

    $SO_FILE ||= $ENV{SO_OBO};
    $SO_FILE ||= 'curl -s http://www.sequenceontology.org/resources/obo_files/current_release.obo |';
    open (my $IN, $SO_FILE) or die "FATAL : cant_open_file : $SO_FILE\n";


    my $text = join '', (<$IN>);

    die "FATAL : no_SO_data_available : $SO_FILE (consider using --so_file or check file contents)\n"
      unless $text;

    $text =~ s/.*?\[Term\]/\[Term\]/s;

    my @terms_array = $text =~ /^\[Term\]\n(.*?)\n{2,}/msg;

    my %terms;
    my %map;
    my %graph;
    for my $term_text (@terms_array) {
	my %term;
	my @pairs = split /\n/, $term_text;
	for my $pair (@pairs) {
	    my ($tag, $value) = split /:\s+/, $pair;
	    push @{$term{$tag}}, $value;
	}
	my $id   = $term{id}[0];
	my $name = $term{name}[0];
	$terms{$id} = \%term;
	$map{$name} = $id;
	$map{$id}   = $name;
	$term{is_a} ||= [];
	for my $is_a (@{$term{is_a}}) {
	    my ($is_a_object) = split /\s/, $is_a;
	    $graph{$is_a_object}{is_a}{$id}++;
	}
	$term{relationship} ||= [];
	for my $relationship (@{$term{relationship}}) {
	    my ($predicate, $object) = split /\s+/, $relationship;
	    $graph{$object}{$predicate}{$id}++;
	}
    }
    my %so_data = (terms => \%terms,
		   map   => \%map,
		   graph => \%graph,
		   );

    return \%so_data;
}

#-----------------------------------------------------------------------------

sub get_so_children {

    my ($so_data, $term_id, $relationships, $seen, $children) = @_;

    $term_id = $so_data->{map}{$term_id} unless $term_id =~ /^SO:\d{7}/;
    my $term = $so_data->{terms}{$term_id};

    for my $relationship (keys %{$relationships}) {
	next unless $so_data->{graph}{$term_id}{$relationship};
	map {$children->{$_}++}
	    keys %{$so_data->{graph}{$term_id}{$relationship}};
    }

#    my %these_relationships;
#    $these_relationships{$so_data->{graph}{$term_id}{is_a}}++
#	if $relationships->{is_a};
#    my @more_relationships = @{$so_data->{graph}{$term_id}{relationships}}
#        if exists $so_data->{graph}{$term_id}{relationships};
#    for my $relationship (@more_relationships) {
#	$these_relationships{$so_data->{graph}{$term_id}{relationship}}++;
#    }
#
#    my %these_children;
#    for my $relationship (keys %these_relationships) {
#	map {$these_children{$_}++; $children->{$_}++} @{$term->{relationships}{$relationship}};
#    }


    for my $child (keys %{$children}) {
	next if $seen->{$child};
	$seen->{$child}++;
	my ($seen, $children) = get_so_children($so_data, $child,
						$relationships, $seen,
						$children);
    }
    return ($seen, $children);
}

#-----------------------------------------------------------------------------

sub send_message {

    my ($class, $code, @comments) = @_;

    $class ||= 'WARN';
    $code  ||= 'unknown_warning';
    my $comment = join ' ', @comments;

    my $message = join ' : ', ($class, $code, $comment);

    print STDERR $message;

}

#-----------------------------------------------------------------------------

sub gff_pragmas {


}

#-----------------------------------------------------------------------------

sub gvf_pragmas {


}

#-----------------------------------------------------------------------------

__END__


    elsif ($build eq 'hg18') {
	  %chrs = (chr1  => 247249719,
		   chr2  => 242951149,
		   chr3  => 199501827,
		   chr4  => 191273063,
		   chr5  => 180857866,
		   chr6  => 170899992,
		   chr7  => 158821424,
		   chr8  => 146274826,
		   chr9  => 140273252,
		   chr10 => 135374737,
		   chr11 => 134452384,
		   chr12 => 132349534,
		   chr13 => 114142980,
		   chr14 => 106368585,
		   chr15 => 100338915,
		   chr16 => 88827254,
		   chr17 => 78774742,
		   chr18 => 76117153,
		   chr19 => 63811651,
		   chr20 => 62435964,
		   chr21 => 46944323,
		   chr22 => 49691432,
		   chrX  => 154913754,
		   chrY  => 57772954,
		   chrM  => 16571,
		   );

	  elsif ($build eq 'hg19') {
	  %chrs = (chr1  => 249250621,
		   chr2  => 243199373,
		   chr3  => 198022430,
		   chr4  => 191154276,
		   chr5  => 180915260,
		   chr6  => 171115067,
		   chr7  => 159138663,
		   chr8  => 146364022,
		   chr9  => 141213431,
		   chr10 => 135534747,
		   chr11 => 135006516,
		   chr12 => 133851895,
		   chr13 => 115169878,
		   chr14 => 107349540,
		   chr15 => 102531392,
		   chr16 => 90354753,
		   chr17 => 81195210,
		   chr18 => 78077248,
		   chr19 => 59128983,
		   chr20 => 63025520,
		   chr21 => 48129895,
		   chr22 => 51304566,
		   chrX  => 155270560,
		   chrY  => 59373566,
		   chrM  => 16571,
		   );



# Pseudoautosomal regions
    my %par = ('hg18' => {chrX => {'five_prime'  => [1, 2709520],
				   'three_prime' => [154584238, 154913754]
				   },
				       chrY => {'five_prime'  => [1, 2709520],
				   'three_prime' => [57443438,  57772954]
				   },
			       },
	       'hg19' => {chrX => {'five_prime'  => [60001, 2699520],
				   'three_prime' => [154931044, 155260560],
			       },
			  chrY => {'five_prime'  => [10001, 2649520],
				   'three_prime' => [59034050,  59363566],
			       }
		      },
	       );
